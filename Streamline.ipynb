{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "\t# load the dataset as a numpy array\n",
    "\tdata = read_csv(full_path)\n",
    "\t# Trian Test Split\n",
    "\tdata, test= train_test_split(data, test_size=0.1)\n",
    "\t# retrieve numpy array\n",
    "\tdata = data.values\n",
    "\t# split into input and output elements\n",
    "\tX, y = data[:, :-1], data[:, -1]\n",
    "\treturn X, y,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the dataset\n",
    "full_path = 'creditcard.csv'\n",
    "# load the dataset\n",
    "X, y, test = load_dataset(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reference model\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision-recall area under curve\n",
    "def pr_auc(y_true, probas_pred):\n",
    "\t# calculate precision-recall curve\n",
    "\tp, r, _ = precision_recall_curve(y_true, probas_pred)\n",
    "\t# calculate area under curve\n",
    "\treturn auc(r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# define the model evaluation the metric\n",
    "\tmetric = make_scorer(pr_auc, needs_proba=True)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = evaluate_model(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean PR AUC: 0.762 (0.042)\n"
     ]
    }
   ],
   "source": [
    "# summarize performance\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree\n",
    "- k-Nearest Neighbors\n",
    "- Bagged Decision Trees\n",
    "- Random Forest\n",
    "- Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier, gini,  max=2\n",
      "Mean PR AUC: 0.715 (0.107)\n"
     ]
    }
   ],
   "source": [
    "# define the reference model\n",
    "DTC = DecisionTreeClassifier(criterion='gini',max_depth=2)\n",
    "# evaluate model\n",
    "DTCscores = evaluate_model(X, y, DTC)\n",
    "# summarize performance\n",
    "print('Decision Tree Classifier, gini,  max=2')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(DTCscores), std(DTCscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'criterion':['gini', 'entropy']}\n",
    "\n",
    "DTC_GS = DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "metric = make_scorer(pr_auc, needs_proba=True)\n",
    "\n",
    "clf = GridSearchCV(DTC_GS, parameters,scoring=metric,cv=cv)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DTC_parameters = {'criterion':['gini', 'entropy'],\n",
    "                        'splitter':['best', 'random'],\n",
    "                        'max_depth':[None,5,10,15],\n",
    "                        'min_samples_split':[2,5,10],\n",
    "                        'min_samples_leaf':[1,3,5],\n",
    "                        'min_weight_fraction_leaf':[0,.25,.5],\n",
    "                        'max_features':[None,25,20,15,10,5,3]}\n",
    "\n",
    "final_DTC = DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "metric = make_scorer(pr_auc, needs_proba=True)\n",
    "\n",
    "final_DTC_clf = GridSearchCV(DTC_GS, final_DTC_parameters,scoring=metric,cv=cv)\n",
    "\n",
    "final_DTC_clf.fit(X, y)\n",
    "\n",
    "final_DTC_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid_Search_Best_Params_(model,param_grid):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    metric = make_scorer(pr_auc, needs_proba=True)\n",
    "    final = GridSearchCV(model, param_grid,scoring=metric,cv=cv)\n",
    "    final.fit(X,y)\n",
    "    return final.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reference model\n",
    "DTC_opt = DecisionTreeClassifier(# will be provided above\n",
    "# evaluate model\n",
    "DTC_optscores = evaluate_model(X, y, model)\n",
    "# summarize performance\n",
    "print('Optimized Decision Tree')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(DTC_optscores), std(DTC_optscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kNN_parameters = {}\n",
    "\n",
    "steps = [('s',StandardScaler()),('m',KNeighborsClassifier())]\n",
    "final_kNN = Pipeline(steps=steps)\n",
    "\n",
    "Grid_Search_Best_Params_(final_kNN,final_kNN_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the reference model\n",
    "steps = [('s',StandardScaler()),('m',KNeighborsClassifier(# will be provided above))]\n",
    "kNN_opt = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "kNN_optscores = evaluate_model(X, y, kNN_opt)\n",
    "# summarize performance\n",
    "print('Optimized k Nearest Neighbors')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(kNN_optscores), std(kNN_optscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_BAG_parameters = {}\n",
    "\n",
    "final_BAG = BaggingClassifier(n_estimators=100)\n",
    "\n",
    "best_BAG_param = Grid_Search_Best_Params_(final_BAG,final_BAG_parameters)\n",
    "\n",
    "BAG_opt = BaggingClassifier(n_estimators=100,best_BAG_param)\n",
    "# evaluate model\n",
    "BAG_optscores = evaluate_model(X, y, BAG_opt)\n",
    "# summarize performance\n",
    "print('Optimized Bagging Classifier')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(BAG_optscores), std(BAG_optscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_RF_parameters = {}\n",
    "\n",
    "final_RF = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "best_RF_param = Grid_Search_Best_Params_(final_RF,final_RF_parameters)\n",
    "\n",
    "RF_opt = RandomForestClassifier(n_estimators=100,best_RF_param)\n",
    "# evaluate model\n",
    "RF_optscores = evaluate_model(X, y, RF_opt)\n",
    "# summarize performance\n",
    "print('Optimized Random Forest')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(RF_optscores), std(RF_optscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ET_parameters = {}\n",
    "\n",
    "final_ET = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "best_ET_param = Grid_Search_Best_Params_(final_ET,final_ET_parameters)\n",
    "\n",
    "ET_opt = RandomForestClassifier(n_estimators=100,best_ET_param)\n",
    "# evaluate model\n",
    "EF_optscores = evaluate_model(X, y, ET_opt)\n",
    "# summarize performance\n",
    "print('Optimized Extra Trees')\n",
    "print('Mean PR AUC: %.3f (%.3f)' % (mean(ET_optscores), std(ET_optscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
